{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implementaion for the Finger Orientaion Model\n",
    "\n",
    "This model was not used in the paper, we model has some slight variations to the paper model. In contrast to the paper, here we use an RMSprop optimizer with a declining learning rate. Hyperparameter of the optimizer are randomly chosen and are not tuned to achieve the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 1.47 s, total: 3.82 s\n",
      "Wall time: 3.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_pickle('./data/all_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MatrixCroppedSameSize = df.MatrixCroppedSameSize.apply(lambda x: np.multiply(x, 1.0 / 255.0))\n",
    "\n",
    "if (tf.keras.backend.image_data_format() == 'channels_last'):\n",
    "    df.MatrixCroppedSameSize = df.MatrixCroppedSameSize.apply(lambda x: x.reshape(22,15,1))\n",
    "else:\n",
    "    df.MatrixCroppedSameSize = df.MatrixCroppedSameSize.apply(lambda x: x.reshape(1,22,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants in the train data set [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26]\n",
      "Participants in the  test data set [27 28 29 30 31 32 33]\n"
     ]
    }
   ],
   "source": [
    "split = (80, 20)\n",
    "ps = np.array(sorted(df.Participant.unique()))\n",
    "num_pt = len(ps)\n",
    "x1 = (int)(np.floor(len(ps) * split[0] / 100.0))\n",
    "split_train = ps[:x1]\n",
    "x2 = (int)(np.floor(len(ps) * split[1] / 100.0))\n",
    "split_test = ps[x1:]\n",
    "dfTest = df[df.Participant.isin(split_test)]\n",
    "dfTrain = df[df.Participant.isin(split_train)]\n",
    "print(\"Participants in the train data set %s\" % split_train)\n",
    "print(\"Participants in the  test data set %s\" % split_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the imapge to tain: (22, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = dfTest.iloc[0].MatrixCroppedSameSize.shape\n",
    "\n",
    "print(\"Shape of the imapge to tain: \" + str(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 244 ms, total: 1.58 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = np.stack(dfTrain.MatrixCroppedSameSize.values, axis=0)\n",
    "y_train = np.stack(dfTrain[[\"Pitch\", \"Yaw\"]].values, axis=0)\n",
    "x_test  = np.stack(dfTest.MatrixCroppedSameSize.values, axis=0)\n",
    "y_test  = np.stack(dfTest[[\"Pitch\", \"Yaw\"]].values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 22, 15, 32)        1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 8, 72)         83016     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 4, 72)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 4, 160)         564640    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 2, 160)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000)              1922000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 4002      \n",
      "=================================================================\n",
      "Total params: 2,574,842\n",
      "Trainable params: 2,574,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 368836 samples, validate on 88432 samples\n",
      "Epoch 1/50\n",
      "368836/368836 [==============================] - 57s 154us/step - loss: 1297.6785 - val_loss: 1432.2032\n",
      "RMSE: 53.29 RMSE-P: 15.92 RMSE-Y: 50.43 e: 56.66 E-P: 13.17 E-Y: 43.49 std: 26.91 std-P: 8.94 std-Y: 25.53\n",
      "Epoch 2/50\n",
      "368836/368836 [==============================] - 98s 266us/step - loss: 1273.4792 - val_loss: 1417.8070\n",
      "RMSE: 53.01 RMSE-P: 15.73 RMSE-Y: 50.24 e: 56.30 E-P: 13.01 E-Y: 43.29 std: 26.86 std-P: 8.83 std-Y: 25.50\n",
      "Epoch 3/50\n",
      "368836/368836 [==============================] - 118s 319us/step - loss: 1260.7966 - val_loss: 1403.1213\n",
      "RMSE: 52.72 RMSE-P: 15.66 RMSE-Y: 49.98 e: 55.96 E-P: 12.95 E-Y: 43.01 std: 26.82 std-P: 8.80 std-Y: 25.46\n",
      "Epoch 4/50\n",
      "368836/368836 [==============================] - 119s 322us/step - loss: 1246.0762 - val_loss: 1388.5334\n",
      "RMSE: 52.37 RMSE-P: 15.74 RMSE-Y: 49.66 e: 55.68 E-P: 13.02 E-Y: 42.66 std: 26.80 std-P: 8.84 std-Y: 25.42\n",
      "Epoch 5/50\n",
      "368836/368836 [==============================] - 120s 325us/step - loss: 1229.2352 - val_loss: 1369.9018\n",
      "RMSE: 51.94 RMSE-P: 15.71 RMSE-Y: 49.29 e: 55.24 E-P: 13.00 E-Y: 42.25 std: 26.78 std-P: 8.83 std-Y: 25.39\n",
      "Epoch 6/50\n",
      "368836/368836 [==============================] - 120s 326us/step - loss: 1210.6840 - val_loss: 1348.3692\n",
      "RMSE: 51.42 RMSE-P: 15.61 RMSE-Y: 48.87 e: 54.69 E-P: 12.92 E-Y: 41.78 std: 26.76 std-P: 8.78 std-Y: 25.37\n",
      "Epoch 7/50\n",
      "368836/368836 [==============================] - 121s 328us/step - loss: 1190.9033 - val_loss: 1326.6183\n",
      "RMSE: 50.87 RMSE-P: 15.56 RMSE-Y: 48.44 e: 54.13 E-P: 12.87 E-Y: 41.26 std: 26.78 std-P: 8.74 std-Y: 25.37\n",
      "Epoch 8/50\n",
      "368836/368836 [==============================] - 121s 328us/step - loss: 1170.5032 - val_loss: 1304.1088\n",
      "RMSE: 50.35 RMSE-P: 15.52 RMSE-Y: 47.97 e: 53.57 E-P: 12.84 E-Y: 40.72 std: 26.78 std-P: 8.72 std-Y: 25.36\n",
      "Epoch 9/50\n",
      "368836/368836 [==============================] - 121s 327us/step - loss: 1149.9464 - val_loss: 1282.6303\n",
      "RMSE: 49.82 RMSE-P: 15.54 RMSE-Y: 47.51 e: 53.02 E-P: 12.86 E-Y: 40.17 std: 26.82 std-P: 8.73 std-Y: 25.37\n",
      "Epoch 10/50\n",
      "368836/368836 [==============================] - 119s 321us/step - loss: 1129.7402 - val_loss: 1261.1967\n",
      "RMSE: 49.35 RMSE-P: 15.55 RMSE-Y: 47.04 e: 52.48 E-P: 12.87 E-Y: 39.62 std: 26.84 std-P: 8.73 std-Y: 25.37\n",
      "Epoch 11/50\n",
      "368836/368836 [==============================] - 120s 324us/step - loss: 1110.3730 - val_loss: 1240.1499\n",
      "RMSE: 48.85 RMSE-P: 15.51 RMSE-Y: 46.60 e: 51.91 E-P: 12.83 E-Y: 39.07 std: 26.86 std-P: 8.70 std-Y: 25.39\n",
      "Epoch 12/50\n",
      "368836/368836 [==============================] - 120s 326us/step - loss: 1092.0135 - val_loss: 1221.6847\n",
      "RMSE: 48.42 RMSE-P: 15.55 RMSE-Y: 46.18 e: 51.43 E-P: 12.87 E-Y: 38.56 std: 26.89 std-P: 8.72 std-Y: 25.40\n",
      "Epoch 13/50\n",
      "368836/368836 [==============================] - 120s 326us/step - loss: 1074.9812 - val_loss: 1203.1384\n",
      "RMSE: 47.98 RMSE-P: 15.50 RMSE-Y: 45.78 e: 50.91 E-P: 12.83 E-Y: 38.08 std: 26.90 std-P: 8.69 std-Y: 25.41\n",
      "Epoch 14/50\n",
      "368836/368836 [==============================] - 120s 325us/step - loss: 1059.2182 - val_loss: 1186.5609\n",
      "RMSE: 47.61 RMSE-P: 15.51 RMSE-Y: 45.41 e: 50.47 E-P: 12.84 E-Y: 37.63 std: 26.89 std-P: 8.69 std-Y: 25.40\n",
      "Epoch 15/50\n",
      "368836/368836 [==============================] - 120s 325us/step - loss: 1044.7549 - val_loss: 1172.1705\n",
      "RMSE: 47.28 RMSE-P: 15.56 RMSE-Y: 45.06 e: 50.11 E-P: 12.89 E-Y: 37.23 std: 26.90 std-P: 8.72 std-Y: 25.39\n",
      "Epoch 16/50\n",
      "368836/368836 [==============================] - 119s 323us/step - loss: 1031.6017 - val_loss: 1158.3760\n",
      "RMSE: 46.99 RMSE-P: 15.58 RMSE-Y: 44.74 e: 49.76 E-P: 12.90 E-Y: 36.86 std: 26.88 std-P: 8.72 std-Y: 25.36\n",
      "Epoch 17/50\n",
      "368836/368836 [==============================] - 119s 324us/step - loss: 1019.6906 - val_loss: 1146.0422\n",
      "RMSE: 46.68 RMSE-P: 15.57 RMSE-Y: 44.46 e: 49.42 E-P: 12.90 E-Y: 36.52 std: 26.87 std-P: 8.72 std-Y: 25.35\n",
      "Epoch 18/50\n",
      "368836/368836 [==============================] - 119s 323us/step - loss: 1009.0744 - val_loss: 1134.8885\n",
      "RMSE: 46.44 RMSE-P: 15.59 RMSE-Y: 44.19 e: 49.14 E-P: 12.92 E-Y: 36.22 std: 26.85 std-P: 8.73 std-Y: 25.32\n",
      "Epoch 19/50\n",
      "368836/368836 [==============================] - 118s 319us/step - loss: 999.4502 - val_loss: 1124.9117\n",
      "RMSE: 46.22 RMSE-P: 15.60 RMSE-Y: 43.96 e: 48.88 E-P: 12.93 E-Y: 35.95 std: 26.83 std-P: 8.73 std-Y: 25.29\n",
      "Epoch 20/50\n",
      "368836/368836 [==============================] - 120s 324us/step - loss: 990.8440 - val_loss: 1116.7606\n",
      "RMSE: 46.01 RMSE-P: 15.65 RMSE-Y: 43.75 e: 48.68 E-P: 12.97 E-Y: 35.70 std: 26.83 std-P: 8.76 std-Y: 25.28\n",
      "Epoch 21/50\n",
      "368836/368836 [==============================] - 121s 329us/step - loss: 983.1347 - val_loss: 1107.9844\n",
      "RMSE: 45.84 RMSE-P: 15.63 RMSE-Y: 43.55 e: 48.44 E-P: 12.96 E-Y: 35.48 std: 26.80 std-P: 8.75 std-Y: 25.25\n",
      "Epoch 22/50\n",
      "368836/368836 [==============================] - 122s 331us/step - loss: 976.2573 - val_loss: 1100.3614\n",
      "RMSE: 45.69 RMSE-P: 15.64 RMSE-Y: 43.37 e: 48.24 E-P: 12.96 E-Y: 35.28 std: 26.77 std-P: 8.75 std-Y: 25.21\n",
      "Epoch 23/50\n",
      "368836/368836 [==============================] - 120s 325us/step - loss: 970.1301 - val_loss: 1094.0855\n",
      "RMSE: 45.53 RMSE-P: 15.65 RMSE-Y: 43.21 e: 48.08 E-P: 12.97 E-Y: 35.10 std: 26.76 std-P: 8.75 std-Y: 25.20\n",
      "Epoch 24/50\n",
      "368836/368836 [==============================] - 120s 326us/step - loss: 964.5627 - val_loss: 1088.3624\n",
      "RMSE: 45.43 RMSE-P: 15.69 RMSE-Y: 43.06 e: 47.94 E-P: 13.00 E-Y: 34.94 std: 26.75 std-P: 8.77 std-Y: 25.17\n",
      "Epoch 25/50\n",
      "368836/368836 [==============================] - 121s 328us/step - loss: 959.4903 - val_loss: 1082.7441\n",
      "RMSE: 45.31 RMSE-P: 15.69 RMSE-Y: 42.93 e: 47.80 E-P: 13.00 E-Y: 34.79 std: 26.73 std-P: 8.77 std-Y: 25.15\n",
      "Epoch 26/50\n",
      "368836/368836 [==============================] - 119s 323us/step - loss: 954.8975 - val_loss: 1078.0642\n",
      "RMSE: 45.20 RMSE-P: 15.71 RMSE-Y: 42.81 e: 47.68 E-P: 13.02 E-Y: 34.66 std: 26.72 std-P: 8.78 std-Y: 25.13\n",
      "Epoch 27/50\n",
      "368836/368836 [==============================] - 121s 327us/step - loss: 950.7540 - val_loss: 1073.8402\n",
      "RMSE: 45.12 RMSE-P: 15.74 RMSE-Y: 42.69 e: 47.58 E-P: 13.05 E-Y: 34.53 std: 26.72 std-P: 8.80 std-Y: 25.11\n",
      "Epoch 28/50\n",
      "368836/368836 [==============================] - 118s 321us/step - loss: 946.8863 - val_loss: 1069.2757\n",
      "RMSE: 45.01 RMSE-P: 15.72 RMSE-Y: 42.59 e: 47.45 E-P: 13.04 E-Y: 34.41 std: 26.70 std-P: 8.79 std-Y: 25.09\n",
      "Epoch 29/50\n",
      "368836/368836 [==============================] - 120s 326us/step - loss: 943.2868 - val_loss: 1065.3984\n",
      "RMSE: 44.93 RMSE-P: 15.73 RMSE-Y: 42.49 e: 47.35 E-P: 13.05 E-Y: 34.31 std: 26.69 std-P: 8.80 std-Y: 25.07\n",
      "Epoch 30/50\n",
      "368836/368836 [==============================] - 120s 326us/step - loss: 939.9559 - val_loss: 1061.9787\n",
      "RMSE: 44.85 RMSE-P: 15.75 RMSE-Y: 42.40 e: 47.27 E-P: 13.06 E-Y: 34.21 std: 26.68 std-P: 8.80 std-Y: 25.06\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368836/368836 [==============================] - 122s 330us/step - loss: 936.9019 - val_loss: 1058.8702\n",
      "RMSE: 44.80 RMSE-P: 15.78 RMSE-Y: 42.32 e: 47.20 E-P: 13.08 E-Y: 34.11 std: 26.68 std-P: 8.82 std-Y: 25.04\n",
      "Epoch 32/50\n",
      "368836/368836 [==============================] - 121s 328us/step - loss: 934.0718 - val_loss: 1055.5248\n",
      "RMSE: 44.73 RMSE-P: 15.77 RMSE-Y: 42.24 e: 47.11 E-P: 13.08 E-Y: 34.03 std: 26.66 std-P: 8.82 std-Y: 25.03\n",
      "Epoch 33/50\n",
      "368836/368836 [==============================] - 122s 330us/step - loss: 931.3946 - val_loss: 1052.9099\n",
      "RMSE: 44.65 RMSE-P: 15.79 RMSE-Y: 42.17 e: 47.04 E-P: 13.09 E-Y: 33.95 std: 26.66 std-P: 8.82 std-Y: 25.02\n",
      "Epoch 34/50\n",
      "368836/368836 [==============================] - 123s 333us/step - loss: 928.9233 - val_loss: 1049.8080\n",
      "RMSE: 44.61 RMSE-P: 15.78 RMSE-Y: 42.10 e: 46.95 E-P: 13.08 E-Y: 33.87 std: 26.64 std-P: 8.82 std-Y: 25.00\n",
      "Epoch 35/50\n",
      "368836/368836 [==============================] - 121s 328us/step - loss: 926.5872 - val_loss: 1047.8299\n",
      "RMSE: 44.55 RMSE-P: 15.81 RMSE-Y: 42.04 e: 46.91 E-P: 13.11 E-Y: 33.80 std: 26.65 std-P: 8.84 std-Y: 24.99\n",
      "Epoch 36/50\n",
      "368836/368836 [==============================] - 119s 323us/step - loss: 924.3742 - val_loss: 1045.2232\n",
      "RMSE: 44.48 RMSE-P: 15.80 RMSE-Y: 41.98 e: 46.84 E-P: 13.10 E-Y: 33.73 std: 26.64 std-P: 8.83 std-Y: 24.98\n",
      "Epoch 37/50\n",
      "368836/368836 [==============================] - 122s 330us/step - loss: 922.2791 - val_loss: 1042.7507\n",
      "RMSE: 44.44 RMSE-P: 15.80 RMSE-Y: 41.92 e: 46.77 E-P: 13.10 E-Y: 33.67 std: 26.63 std-P: 8.83 std-Y: 24.97\n",
      "Epoch 38/50\n",
      "368836/368836 [==============================] - 122s 331us/step - loss: 920.2828 - val_loss: 1040.7043\n",
      "RMSE: 44.40 RMSE-P: 15.81 RMSE-Y: 41.86 e: 46.72 E-P: 13.11 E-Y: 33.61 std: 26.63 std-P: 8.84 std-Y: 24.96\n",
      "Epoch 39/50\n",
      "368836/368836 [==============================] - 119s 323us/step - loss: 918.4050 - val_loss: 1038.7465\n",
      "RMSE: 44.38 RMSE-P: 15.83 RMSE-Y: 41.81 e: 46.68 E-P: 13.13 E-Y: 33.55 std: 26.62 std-P: 8.85 std-Y: 24.95\n",
      "Epoch 40/50\n",
      "368836/368836 [==============================] - 120s 325us/step - loss: 916.6138 - val_loss: 1036.5601\n",
      "RMSE: 44.34 RMSE-P: 15.82 RMSE-Y: 41.76 e: 46.61 E-P: 13.12 E-Y: 33.50 std: 26.61 std-P: 8.84 std-Y: 24.94\n",
      "Epoch 41/50\n",
      "368836/368836 [==============================] - 121s 328us/step - loss: 914.9226 - val_loss: 1035.0690\n",
      "RMSE: 44.28 RMSE-P: 15.84 RMSE-Y: 41.71 e: 46.58 E-P: 13.14 E-Y: 33.44 std: 26.61 std-P: 8.85 std-Y: 24.93\n",
      "Epoch 42/50\n",
      "368836/368836 [==============================] - 120s 325us/step - loss: 913.3031 - val_loss: 1033.1085\n",
      "RMSE: 44.24 RMSE-P: 15.83 RMSE-Y: 41.67 e: 46.52 E-P: 13.13 E-Y: 33.40 std: 26.60 std-P: 8.85 std-Y: 24.92\n",
      "Epoch 43/50\n",
      "368836/368836 [==============================] - 122s 331us/step - loss: 911.7411 - val_loss: 1031.2588\n",
      "RMSE: 44.20 RMSE-P: 15.83 RMSE-Y: 41.63 e: 46.47 E-P: 13.12 E-Y: 33.35 std: 26.59 std-P: 8.85 std-Y: 24.91\n",
      "Epoch 44/50\n",
      "368836/368836 [==============================] - 122s 332us/step - loss: 910.2483 - val_loss: 1029.8262\n",
      "RMSE: 44.19 RMSE-P: 15.85 RMSE-Y: 41.58 e: 46.44 E-P: 13.14 E-Y: 33.30 std: 26.59 std-P: 8.86 std-Y: 24.90\n",
      "Epoch 45/50\n",
      "368836/368836 [==============================] - 121s 329us/step - loss: 908.8241 - val_loss: 1028.3196\n",
      "RMSE: 44.12 RMSE-P: 15.84 RMSE-Y: 41.55 e: 46.40 E-P: 13.14 E-Y: 33.26 std: 26.59 std-P: 8.86 std-Y: 24.89\n",
      "Epoch 46/50\n",
      "368836/368836 [==============================] - 121s 329us/step - loss: 907.4654 - val_loss: 1026.7697\n",
      "RMSE: 44.11 RMSE-P: 15.85 RMSE-Y: 41.51 e: 46.36 E-P: 13.14 E-Y: 33.22 std: 26.58 std-P: 8.86 std-Y: 24.88\n",
      "Epoch 47/50\n",
      "368836/368836 [==============================] - 120s 325us/step - loss: 906.1527 - val_loss: 1025.5433\n",
      "RMSE: 44.09 RMSE-P: 15.87 RMSE-Y: 41.47 e: 46.34 E-P: 13.16 E-Y: 33.18 std: 26.58 std-P: 8.87 std-Y: 24.87\n",
      "Epoch 48/50\n",
      "368836/368836 [==============================] - 122s 330us/step - loss: 904.8776 - val_loss: 1023.9692\n",
      "RMSE: 44.03 RMSE-P: 15.85 RMSE-Y: 41.44 e: 46.29 E-P: 13.14 E-Y: 33.15 std: 26.57 std-P: 8.86 std-Y: 24.87\n",
      "Epoch 49/50\n",
      "368836/368836 [==============================] - 122s 330us/step - loss: 903.6699 - val_loss: 1022.5280\n",
      "RMSE: 44.02 RMSE-P: 15.85 RMSE-Y: 41.40 e: 46.25 E-P: 13.14 E-Y: 33.11 std: 26.56 std-P: 8.86 std-Y: 24.86\n",
      "Epoch 50/50\n",
      "368836/368836 [==============================] - 121s 329us/step - loss: 902.4962 - val_loss: 1021.4516\n",
      "RMSE: 43.99 RMSE-P: 15.86 RMSE-Y: 41.37 e: 46.23 E-P: 13.15 E-Y: 33.07 std: 26.56 std-P: 8.87 std-Y: 24.85\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 27, 15\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True, device_count = {'GPU' : 4})\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction=1.0\n",
    "#config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    session = tf.Session(config=config)\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(6, 6),\n",
    "                                     activation='relu',\n",
    "                                     padding='same',\n",
    "                                     bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "                                     input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(72, kernel_size=(6, 6),\n",
    "                                     activation='relu',\n",
    "                                     bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "                                     padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(160, kernel_size=(7, 7),\n",
    "                                     activation='relu',\n",
    "                                     bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "                                     padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(2000, \n",
    "            activation='relu',\n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "            bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.15)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(2,\n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "            bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.15)))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss=tf.keras.losses.mean_squared_error,\n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    # Function to display the target and prediciton\n",
    "    def testmodel(epoch, logs):\n",
    "        pred_y = model.predict(\n",
    "            x_test,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        true_y = y_test\n",
    "        \n",
    "        ePitch = np.abs(true_y[:,0] - pred_y[:,0]) \n",
    "        eYaw = np.abs(true_y[:,1] - pred_y[:,1])\n",
    "        ListError = ePitch + eYaw\n",
    "        ListErrorPitch = ePitch\n",
    "        ListErrorYaw = eYaw\n",
    "\n",
    "        diff_true = true_y[:,0] + true_y[:,1]\n",
    "        diff_pred = pred_y[:,0] + pred_y[:,1]\n",
    "        RMSE = np.sqrt(np.mean(np.square(np.subtract(diff_pred, diff_true))))\n",
    "        RMSEPitch = np.sqrt(np.mean(np.square(np.subtract(pred_y[:,0], true_y[:,0]))))\n",
    "        RMSEYaw   = np.sqrt(np.mean(np.square(np.subtract(pred_y[:,1], true_y[:,1]))))\n",
    "        \n",
    "        print ('RMSE: %.2f RMSE-P: %.2f RMSE-Y: %.2f e: %.2f E-P: %.2f E-Y: %.2f std: %.2f std-P: %.2f std-Y: %.2f' %(\n",
    "                  RMSE, RMSEPitch, RMSEYaw,\n",
    "                    ListError.mean(), ListErrorPitch.mean(), ListErrorYaw.mean(),\n",
    "                    ListError.std(), ListErrorPitch.std(), ListErrorYaw.std(),))\n",
    "\n",
    "    \n",
    "    # Callback to display the target and prediciton\n",
    "    testcallback = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=50,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[testcallback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
