{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implementaion for the Finger Orientaion Model\n",
    "\n",
    "This model was not used in the paper, we model has some slight variations to the paper model. In contrast to the paper, here we use an RMSprop optimizer with a declining learning rate. Hyperparameter of the optimizer are randomly chosen and are not tuned to achieve the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 1.85 s, total: 3.54 s\n",
      "Wall time: 3.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_pickle('./data/all_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MatrixCroppedSameSize = df.MatrixCroppedSameSize.apply(lambda x: np.multiply(x, 1.0 / 255.0))\n",
    "\n",
    "if (tf.keras.backend.image_data_format() == 'channels_last'):\n",
    "    df.MatrixCroppedSameSize = df.MatrixCroppedSameSize.apply(lambda x: x.reshape(22,15,1))\n",
    "else:\n",
    "    df.MatrixCroppedSameSize = df.MatrixCroppedSameSize.apply(lambda x: x.reshape(1,22,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants in the train data set [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26]\n",
      "Participants in the  test data set [27 28 29 30 31 32 33]\n"
     ]
    }
   ],
   "source": [
    "split = (80, 20)\n",
    "ps = np.array(sorted(df.Participant.unique()))\n",
    "num_pt = len(ps)\n",
    "x1 = (int)(np.floor(len(ps) * split[0] / 100.0))\n",
    "split_train = ps[:x1]\n",
    "x2 = (int)(np.floor(len(ps) * split[1] / 100.0))\n",
    "split_test = ps[x1:]\n",
    "dfTest = df[df.Participant.isin(split_test)]\n",
    "dfTrain = df[df.Participant.isin(split_train)]\n",
    "print(\"Participants in the train data set %s\" % split_train)\n",
    "print(\"Participants in the  test data set %s\" % split_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the imapge to tain: (22, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = dfTest.iloc[0].MatrixCroppedSameSize.shape\n",
    "\n",
    "print(\"Shape of the imapge to tain: \" + str(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 142 ms, total: 1.27 s\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = np.stack(dfTrain.MatrixCroppedSameSize.values, axis=0)\n",
    "y_train = np.stack(dfTrain[[\"Pitch\", \"Yaw\"]].values, axis=0)\n",
    "x_test  = np.stack(dfTest.MatrixCroppedSameSize.values, axis=0)\n",
    "y_test  = np.stack(dfTest[[\"Pitch\", \"Yaw\"]].values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 22, 15, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 11, 8, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 8, 72)         83016     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 4, 72)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 4, 160)         564640    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 2, 160)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 960)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2000)              1922000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 4002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,574,842\n",
      "Trainable params: 2,574,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 03:58:13.976046: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-12 03:58:14.546815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30990 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 03:58:17.375796: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-05-12 03:58:18.036449: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - ETA: 0s - loss: 1282.1387\n",
      "RMSE: 52.41 RMSE-P: 15.60 RMSE-Y: 49.83 e: 55.76 E-P: 12.90 E-Y: 42.86 std: 26.85 std-P: 8.78 std-Y: 25.42\n",
      "3689/3689 [==============================] - 34s 9ms/step - loss: 1282.1387 - val_loss: 1397.4166\n",
      "Epoch 2/50\n",
      "3689/3689 [==============================] - ETA: 0s - loss: 1213.2039\n",
      "RMSE: 50.54 RMSE-P: 15.79 RMSE-Y: 48.15 e: 54.04 E-P: 13.06 E-Y: 40.97 std: 26.80 std-P: 8.87 std-Y: 25.28\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 1213.2039 - val_loss: 1318.4746\n",
      "Epoch 3/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 1128.7214\n",
      "RMSE: 48.49 RMSE-P: 15.68 RMSE-Y: 46.24 e: 51.69 E-P: 12.99 E-Y: 38.70 std: 26.82 std-P: 8.77 std-Y: 25.31\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 1128.6033 - val_loss: 1228.5409\n",
      "Epoch 4/50\n",
      "3687/3689 [============================>.] - ETA: 0s - loss: 1054.8794\n",
      "RMSE: 47.05 RMSE-P: 15.77 RMSE-Y: 44.73 e: 49.95 E-P: 13.09 E-Y: 36.87 std: 26.86 std-P: 8.80 std-Y: 25.32\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 1054.9274 - val_loss: 1162.5125\n",
      "Epoch 5/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 1004.4042\n",
      "RMSE: 46.11 RMSE-P: 15.82 RMSE-Y: 43.73 e: 48.81 E-P: 13.14 E-Y: 35.67 std: 26.86 std-P: 8.81 std-Y: 25.29\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 1004.3826 - val_loss: 1120.1680\n",
      "Epoch 6/50\n",
      "3682/3689 [============================>.] - ETA: 0s - loss: 973.0280\n",
      "RMSE: 45.58 RMSE-P: 15.89 RMSE-Y: 43.05 e: 48.10 E-P: 13.20 E-Y: 34.89 std: 26.84 std-P: 8.84 std-Y: 25.22\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 972.9573 - val_loss: 1092.8154\n",
      "Epoch 7/50\n",
      "3684/3689 [============================>.] - ETA: 0s - loss: 952.5955\n",
      "RMSE: 45.21 RMSE-P: 15.85 RMSE-Y: 42.59 e: 47.54 E-P: 13.17 E-Y: 34.37 std: 26.79 std-P: 8.82 std-Y: 25.16\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 952.6435 - val_loss: 1072.9806\n",
      "Epoch 8/50\n",
      "3689/3689 [==============================] - ETA: 0s - loss: 938.6203\n",
      "RMSE: 44.90 RMSE-P: 15.93 RMSE-Y: 42.26 e: 47.23 E-P: 13.24 E-Y: 33.99 std: 26.79 std-P: 8.86 std-Y: 25.12\n",
      "3689/3689 [==============================] - 32s 9ms/step - loss: 938.6203 - val_loss: 1060.5303\n",
      "Epoch 9/50\n",
      "3683/3689 [============================>.] - ETA: 0s - loss: 928.3563\n",
      "RMSE: 44.74 RMSE-P: 15.94 RMSE-Y: 42.01 e: 46.95 E-P: 13.24 E-Y: 33.70 std: 26.76 std-P: 8.87 std-Y: 25.07\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 928.3206 - val_loss: 1050.2473\n",
      "Epoch 10/50\n",
      "3682/3689 [============================>.] - ETA: 0s - loss: 920.4078\n",
      "RMSE: 44.56 RMSE-P: 15.96 RMSE-Y: 41.81 e: 46.74 E-P: 13.26 E-Y: 33.48 std: 26.75 std-P: 8.88 std-Y: 25.04\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 920.4477 - val_loss: 1042.3671\n",
      "Epoch 11/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 913.9705\n",
      "RMSE: 44.41 RMSE-P: 15.94 RMSE-Y: 41.64 e: 46.54 E-P: 13.24 E-Y: 33.30 std: 26.71 std-P: 8.87 std-Y: 25.00\n",
      "3689/3689 [==============================] - 32s 9ms/step - loss: 914.0058 - val_loss: 1035.1450\n",
      "Epoch 12/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 908.6090\n",
      "RMSE: 44.29 RMSE-P: 15.97 RMSE-Y: 41.50 e: 46.41 E-P: 13.26 E-Y: 33.15 std: 26.71 std-P: 8.89 std-Y: 24.97\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 908.6459 - val_loss: 1029.9696\n",
      "Epoch 13/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 904.0687\n",
      "RMSE: 44.18 RMSE-P: 15.96 RMSE-Y: 41.38 e: 46.28 E-P: 13.26 E-Y: 33.02 std: 26.68 std-P: 8.89 std-Y: 24.94\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 904.0598 - val_loss: 1025.0026\n",
      "Epoch 14/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 900.1026\n",
      "RMSE: 44.09 RMSE-P: 15.98 RMSE-Y: 41.28 e: 46.18 E-P: 13.27 E-Y: 32.91 std: 26.67 std-P: 8.90 std-Y: 24.92\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 900.0946 - val_loss: 1020.9861\n",
      "Epoch 15/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 896.5663\n",
      "RMSE: 43.98 RMSE-P: 15.98 RMSE-Y: 41.19 e: 46.09 E-P: 13.27 E-Y: 32.82 std: 26.66 std-P: 8.90 std-Y: 24.89\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 896.6358 - val_loss: 1017.5056\n",
      "Epoch 16/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 893.6154\n",
      "RMSE: 43.93 RMSE-P: 15.99 RMSE-Y: 41.11 e: 46.00 E-P: 13.27 E-Y: 32.73 std: 26.64 std-P: 8.91 std-Y: 24.87\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 893.5516 - val_loss: 1014.1339\n",
      "Epoch 17/50\n",
      "3683/3689 [============================>.] - ETA: 0s - loss: 890.7809\n",
      "RMSE: 43.88 RMSE-P: 15.94 RMSE-Y: 41.03 e: 45.88 E-P: 13.23 E-Y: 32.65 std: 26.61 std-P: 8.88 std-Y: 24.85\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 890.7446 - val_loss: 1010.3024\n",
      "Epoch 18/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 888.1346\n",
      "RMSE: 43.78 RMSE-P: 15.96 RMSE-Y: 40.97 e: 45.83 E-P: 13.25 E-Y: 32.58 std: 26.60 std-P: 8.90 std-Y: 24.83\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 888.1787 - val_loss: 1008.0280\n",
      "Epoch 19/50\n",
      "3682/3689 [============================>.] - ETA: 0s - loss: 885.8740\n",
      "RMSE: 43.77 RMSE-P: 15.96 RMSE-Y: 40.90 e: 45.77 E-P: 13.25 E-Y: 32.52 std: 26.59 std-P: 8.90 std-Y: 24.81\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 885.8287 - val_loss: 1005.4150\n",
      "Epoch 20/50\n",
      "3682/3689 [============================>.] - ETA: 0s - loss: 883.6294\n",
      "RMSE: 43.69 RMSE-P: 15.97 RMSE-Y: 40.85 e: 45.71 E-P: 13.25 E-Y: 32.46 std: 26.58 std-P: 8.90 std-Y: 24.80\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 883.6625 - val_loss: 1003.3087\n",
      "Epoch 21/50\n",
      "3684/3689 [============================>.] - ETA: 0s - loss: 881.5765\n",
      "RMSE: 43.66 RMSE-P: 15.97 RMSE-Y: 40.80 e: 45.66 E-P: 13.25 E-Y: 32.41 std: 26.57 std-P: 8.91 std-Y: 24.78\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 881.6742 - val_loss: 1001.1439\n",
      "Epoch 22/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 879.7587\n",
      "RMSE: 43.64 RMSE-P: 15.98 RMSE-Y: 40.75 e: 45.62 E-P: 13.26 E-Y: 32.36 std: 26.56 std-P: 8.91 std-Y: 24.76\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 879.8176 - val_loss: 999.3722\n",
      "Epoch 23/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 878.0836\n",
      "RMSE: 43.60 RMSE-P: 15.95 RMSE-Y: 40.70 e: 45.55 E-P: 13.24 E-Y: 32.31 std: 26.54 std-P: 8.90 std-Y: 24.75\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 878.0877 - val_loss: 997.0908\n",
      "Epoch 24/50\n",
      "3683/3689 [============================>.] - ETA: 0s - loss: 876.4884\n",
      "RMSE: 43.53 RMSE-P: 15.98 RMSE-Y: 40.66 e: 45.53 E-P: 13.26 E-Y: 32.27 std: 26.55 std-P: 8.92 std-Y: 24.73\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 876.4480 - val_loss: 995.8631\n",
      "Epoch 25/50\n",
      "3684/3689 [============================>.] - ETA: 0s - loss: 874.8804\n",
      "RMSE: 43.50 RMSE-P: 15.94 RMSE-Y: 40.62 e: 45.46 E-P: 13.23 E-Y: 32.23 std: 26.52 std-P: 8.90 std-Y: 24.72\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 874.8842 - val_loss: 993.5536\n",
      "Epoch 26/50\n",
      "3682/3689 [============================>.] - ETA: 0s - loss: 873.4875\n",
      "RMSE: 43.47 RMSE-P: 15.96 RMSE-Y: 40.58 e: 45.43 E-P: 13.24 E-Y: 32.19 std: 26.52 std-P: 8.91 std-Y: 24.71\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 873.4373 - val_loss: 992.3037\n",
      "Epoch 27/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 872.0997\n",
      "RMSE: 43.44 RMSE-P: 15.94 RMSE-Y: 40.54 e: 45.38 E-P: 13.22 E-Y: 32.16 std: 26.50 std-P: 8.90 std-Y: 24.70\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 872.0752 - val_loss: 990.4952\n",
      "Epoch 28/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 870.8107\n",
      "RMSE: 43.39 RMSE-P: 15.94 RMSE-Y: 40.51 e: 45.35 E-P: 13.22 E-Y: 32.12 std: 26.49 std-P: 8.90 std-Y: 24.69\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 870.7717 - val_loss: 989.1383\n",
      "Epoch 29/50\n",
      "3682/3689 [============================>.] - ETA: 0s - loss: 869.5372\n",
      "RMSE: 43.39 RMSE-P: 15.94 RMSE-Y: 40.48 e: 45.31 E-P: 13.22 E-Y: 32.09 std: 26.48 std-P: 8.90 std-Y: 24.67\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 869.5269 - val_loss: 987.7808\n",
      "Epoch 30/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 868.2997\n",
      "RMSE: 43.35 RMSE-P: 15.95 RMSE-Y: 40.45 e: 45.29 E-P: 13.23 E-Y: 32.06 std: 26.48 std-P: 8.91 std-Y: 24.66\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 868.3290 - val_loss: 986.6572\n",
      "Epoch 31/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 867.1871\n",
      "RMSE: 43.36 RMSE-P: 15.94 RMSE-Y: 40.42 e: 45.25 E-P: 13.22 E-Y: 32.03 std: 26.47 std-P: 8.90 std-Y: 24.65\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 867.1625 - val_loss: 985.2951\n",
      "Epoch 32/50\n",
      "3682/3689 [============================>.] - ETA: 0s - loss: 866.0667\n",
      "RMSE: 43.29 RMSE-P: 15.93 RMSE-Y: 40.39 e: 45.21 E-P: 13.21 E-Y: 32.00 std: 26.45 std-P: 8.90 std-Y: 24.64\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 866.0756 - val_loss: 983.9435\n",
      "Epoch 33/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 865.0432\n",
      "RMSE: 43.27 RMSE-P: 15.93 RMSE-Y: 40.36 e: 45.19 E-P: 13.22 E-Y: 31.97 std: 26.45 std-P: 8.90 std-Y: 24.63\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 865.0114 - val_loss: 982.9763\n",
      "Epoch 34/50\n",
      "3683/3689 [============================>.] - ETA: 0s - loss: 863.8429\n",
      "RMSE: 43.25 RMSE-P: 15.92 RMSE-Y: 40.34 e: 45.16 E-P: 13.21 E-Y: 31.95 std: 26.44 std-P: 8.90 std-Y: 24.62\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 863.9875 - val_loss: 981.7319\n",
      "Epoch 35/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 863.0095\n",
      "RMSE: 43.23 RMSE-P: 15.93 RMSE-Y: 40.31 e: 45.14 E-P: 13.21 E-Y: 31.92 std: 26.43 std-P: 8.90 std-Y: 24.61\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 863.0064 - val_loss: 980.7825\n",
      "Epoch 36/50\n",
      "3684/3689 [============================>.] - ETA: 0s - loss: 862.0626\n",
      "RMSE: 43.19 RMSE-P: 15.92 RMSE-Y: 40.29 e: 45.11 E-P: 13.21 E-Y: 31.90 std: 26.43 std-P: 8.90 std-Y: 24.60\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 862.0585 - val_loss: 979.7319\n",
      "Epoch 37/50\n",
      "3688/3689 [============================>.] - ETA: 0s - loss: 861.0953\n",
      "RMSE: 43.18 RMSE-P: 15.91 RMSE-Y: 40.26 e: 45.07 E-P: 13.20 E-Y: 31.88 std: 26.41 std-P: 8.89 std-Y: 24.59\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 861.1531 - val_loss: 978.5685\n",
      "Epoch 38/50\n",
      "3689/3689 [==============================] - ETA: 0s - loss: 860.2749\n",
      "RMSE: 43.17 RMSE-P: 15.92 RMSE-Y: 40.24 e: 45.06 E-P: 13.20 E-Y: 31.86 std: 26.41 std-P: 8.90 std-Y: 24.59\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 860.2749 - val_loss: 977.7966\n",
      "Epoch 39/50\n",
      "3689/3689 [==============================] - ETA: 0s - loss: 859.4236\n",
      "RMSE: 43.14 RMSE-P: 15.94 RMSE-Y: 40.22 e: 45.05 E-P: 13.22 E-Y: 31.83 std: 26.41 std-P: 8.91 std-Y: 24.58\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 859.4236 - val_loss: 977.1603\n",
      "Epoch 40/50\n",
      "3687/3689 [============================>.] - ETA: 0s - loss: 858.6305\n",
      "RMSE: 43.14 RMSE-P: 15.93 RMSE-Y: 40.20 e: 45.02 E-P: 13.21 E-Y: 31.81 std: 26.40 std-P: 8.90 std-Y: 24.57\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 858.6036 - val_loss: 976.1368\n",
      "Epoch 41/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 857.8133\n",
      "RMSE: 43.11 RMSE-P: 15.92 RMSE-Y: 40.18 e: 44.99 E-P: 13.20 E-Y: 31.79 std: 26.39 std-P: 8.90 std-Y: 24.56\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 857.8061 - val_loss: 975.1143\n",
      "Epoch 42/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 857.0093\n",
      "RMSE: 43.11 RMSE-P: 15.93 RMSE-Y: 40.16 e: 44.98 E-P: 13.21 E-Y: 31.77 std: 26.39 std-P: 8.90 std-Y: 24.55\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 857.0300 - val_loss: 974.4614\n",
      "Epoch 43/50\n",
      "3682/3689 [============================>.] - ETA: 0s - loss: 856.3371\n",
      "RMSE: 43.07 RMSE-P: 15.92 RMSE-Y: 40.14 e: 44.95 E-P: 13.20 E-Y: 31.75 std: 26.38 std-P: 8.90 std-Y: 24.55\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 856.2798 - val_loss: 973.4981\n",
      "Epoch 44/50\n",
      "3684/3689 [============================>.] - ETA: 0s - loss: 855.5623\n",
      "RMSE: 43.07 RMSE-P: 15.91 RMSE-Y: 40.12 e: 44.93 E-P: 13.19 E-Y: 31.74 std: 26.37 std-P: 8.89 std-Y: 24.54\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 855.5513 - val_loss: 972.5735\n",
      "Epoch 45/50\n",
      "3685/3689 [============================>.] - ETA: 0s - loss: 854.8820\n",
      "RMSE: 43.04 RMSE-P: 15.92 RMSE-Y: 40.10 e: 44.91 E-P: 13.20 E-Y: 31.72 std: 26.37 std-P: 8.90 std-Y: 24.53\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 854.8494 - val_loss: 971.9758\n",
      "Epoch 46/50\n",
      "3683/3689 [============================>.] - ETA: 0s - loss: 854.0789\n",
      "RMSE: 43.02 RMSE-P: 15.91 RMSE-Y: 40.08 e: 44.90 E-P: 13.19 E-Y: 31.70 std: 26.36 std-P: 8.90 std-Y: 24.53\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 854.1531 - val_loss: 971.2325\n",
      "Epoch 47/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 853.4836\n",
      "RMSE: 43.01 RMSE-P: 15.91 RMSE-Y: 40.06 e: 44.88 E-P: 13.19 E-Y: 31.69 std: 26.36 std-P: 8.90 std-Y: 24.52\n",
      "3689/3689 [==============================] - 31s 9ms/step - loss: 853.4803 - val_loss: 970.4988\n",
      "Epoch 48/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 852.7925\n",
      "RMSE: 42.99 RMSE-P: 15.91 RMSE-Y: 40.05 e: 44.86 E-P: 13.19 E-Y: 31.67 std: 26.35 std-P: 8.90 std-Y: 24.51\n",
      "3689/3689 [==============================] - 31s 8ms/step - loss: 852.8174 - val_loss: 969.7171\n",
      "Epoch 49/50\n",
      "3686/3689 [============================>.] - ETA: 0s - loss: 852.2130\n",
      "RMSE: 42.98 RMSE-P: 15.90 RMSE-Y: 40.03 e: 44.83 E-P: 13.18 E-Y: 31.65 std: 26.34 std-P: 8.89 std-Y: 24.51\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 852.1743 - val_loss: 968.8766\n",
      "Epoch 50/50\n",
      "3688/3689 [============================>.] - ETA: 0s - loss: 851.5451\n",
      "RMSE: 42.97 RMSE-P: 15.88 RMSE-Y: 40.01 e: 44.80 E-P: 13.16 E-Y: 31.64 std: 26.33 std-P: 8.88 std-Y: 24.50\n",
      "3689/3689 [==============================] - 30s 8ms/step - loss: 851.5501 - val_loss: 967.9730\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 27, 15\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(6, 6),\n",
    "                                 activation='relu',\n",
    "                                 padding='same',\n",
    "                                 bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "                                 input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(72, kernel_size=(6, 6),\n",
    "                                 activation='relu',\n",
    "                                 bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "                                 padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(160, kernel_size=(7, 7),\n",
    "                                 activation='relu',\n",
    "                                 bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "                                 padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(2000, \n",
    "        activation='relu',\n",
    "        kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "        bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.15)))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(2,\n",
    "        kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "        bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.15)))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mean_squared_error, optimizer=optimizer)\n",
    "\n",
    "# Function to display the target and prediciton\n",
    "def testmodel(epoch, logs):\n",
    "    pred_y = model.predict(\n",
    "        x_test,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    true_y = y_test\n",
    "\n",
    "    ePitch = np.abs(true_y[:,0] - pred_y[:,0]) \n",
    "    eYaw = np.abs(true_y[:,1] - pred_y[:,1])\n",
    "    ListError = ePitch + eYaw\n",
    "    ListErrorPitch = ePitch\n",
    "    ListErrorYaw = eYaw\n",
    "\n",
    "    diff_true = true_y[:,0] + true_y[:,1]\n",
    "    diff_pred = pred_y[:,0] + pred_y[:,1]\n",
    "    RMSE = np.sqrt(np.mean(np.square(np.subtract(diff_pred, diff_true))))\n",
    "    RMSEPitch = np.sqrt(np.mean(np.square(np.subtract(pred_y[:,0], true_y[:,0]))))\n",
    "    RMSEYaw   = np.sqrt(np.mean(np.square(np.subtract(pred_y[:,1], true_y[:,1]))))\n",
    "\n",
    "    print ('\\nRMSE: %.2f RMSE-P: %.2f RMSE-Y: %.2f e: %.2f E-P: %.2f E-Y: %.2f std: %.2f std-P: %.2f std-Y: %.2f' %(\n",
    "              RMSE, RMSEPitch, RMSEYaw,\n",
    "                ListError.mean(), ListErrorPitch.mean(), ListErrorYaw.mean(),\n",
    "                ListError.std(), ListErrorPitch.std(), ListErrorYaw.std(),))\n",
    "\n",
    "\n",
    "# Callback to display the target and prediciton\n",
    "testcallback = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[testcallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f84e4bb6eb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAu4UlEQVR4nO3deXxdZZ348c/3brnZ9yZpkiZtKZS2SYGmUIYdtRQEqziAiAIFRRRQZxgUt8FRcVDn5zYyIiPIMghU0KGyFVTGArI0LV1pKbVr0rTZl2a9uXl+fzwnzW2bPTe5yb3f9+t1Xufc5z733u8p4fuc8zzPOUeMMSillIoNrkgHoJRSauJo0ldKqRiiSV8ppWKIJn2llIohmvSVUiqGeCIdwGCysrJMcXFxpMNQSqkpZd26dbXGmOz+3pvUSb+4uJjy8vJIh6GUUlOKiOwd6D3t3lFKqRiiSV8ppWKIJn2llIohk7pPXykVmwKBABUVFXR0dEQ6lEnN7/dTUFCA1+sd9meGTPoi8iBwKVBtjFlwzHu3A/8BZBtjakVEgJ8BlwBtwPXGmPVO3euAbzof/Z4x5uFhR6mUiikVFRUkJydTXFyMTSvqWMYY6urqqKioYObMmcP+3HC6dx4Clh1bKCKFwFJgX0jxxcAcZ7kJ+KVTNwO4CzgDOB24S0TShx2lUiqmdHR0kJmZqQl/ECJCZmbmiM+Ghkz6xpg1QH0/b/0E+AoQepvO5cAjxnoTSBORPOAi4GVjTL0xpgF4mX4aEqWU6qUJf2ij+Tca1UCuiCwHKo0xG495Kx/YH/K6wikbqLy/775JRMpFpLympmY04UFbPfz1h3DgndF9XimlotSIk76IJABfB/41/OGAMeZ+Y0yZMaYsO7vfC8qG5vLAK9+HHS+FNzilVMxISkqKdAjjYjRH+rOBmcBGEdkDFADrRSQXqAQKQ+oWOGUDlY8Pfwpkz4VKvZpXKaVCjTjpG2M2G2OmGWOKjTHF2K6a04wxB4FVwLViLQGajDFVwGpgqYikOwO4S52y8VNQBhXloE8GU0qNgTGGO+64gwULFlBSUsKTTz4JQFVVFeeeey6nnHIKCxYs4NVXXyUYDHL99dcfqfuTn/wkwtEfbzhTNh8HzgeyRKQCuMsY88AA1Z/HTtfciZ2yuQLAGFMvIt8F1jr1vmOM6W9wOHwKyuCdR6F+F2TOHtefUkqNn3/741bePdAc1u+cNz2Fuy6bP6y6v//979mwYQMbN26ktraWxYsXc+655/Lb3/6Wiy66iG984xsEg0Ha2trYsGEDlZWVbNmyBYDGxsawxh0OQyZ9Y8zVQ7xfHLJtgFsGqPcg8OAI4xu9gsV2XVGuSV8pNWqvvfYaV199NW63m5ycHM477zzWrl3L4sWLueGGGwgEAnz0ox/llFNOYdasWezatYvbbruND3/4wyxdujTS4R8neq/IzZ4LviSoWAsLr4p0NEqpURruEflEO/fcc1mzZg3PPfcc119/Pf/8z//Mtddey8aNG1m9ejX33XcfK1eu5MEHJ+5Ydzii9947LjdMP1UHc5VSY3LOOefw5JNPEgwGqampYc2aNZx++uns3buXnJwcPvvZz/KZz3yG9evXU1tbS09PDx//+Mf53ve+x/r16yMd/nGi90gfbBfP334OgXbwxkc6GqXUFPSxj32MN954g4ULFyIi/PCHPyQ3N5eHH36YH/3oR3i9XpKSknjkkUeorKxkxYoV9PT0APDv//7vEY7+eGIm8eyWsrIyM6aHqGx/Dp74JNzwEsw4I3yBKaXG1bZt2zj55JMjHcaU0N+/lYisM8aU9Vc/ert3APKdfa5YO3g9pZSKEdGd9JNzIG2GJn2llHJEd9IHe7RfuS7SUSil1KQQ/Um/YDE07YfmqkhHopRSERcDSd/p19epm0opFQNJP7cUXF57Za5SSsW46E/6Xj/klWrSV0opYiHpgx3MPfAOBLsjHYlSKgoNdu/9PXv2sGDBggHfn2ixkfQLFkOgFWq2RToSpZSKqOi+DUOvgkV2XbEWcksiG4tSamReuBMObg7vd+aWwMX3DPj2nXfeSWFhIbfcYm8a/O1vfxuPx8Mrr7xCQ0MDgUCA733veyxfvnxEP9vR0cHnP/95ysvL8Xg8/PjHP+aCCy5g69atrFixgq6uLnp6enj66aeZPn06V155JRUVFQSDQb71rW9x1VVjv3lkbCT99JmQkAkV66DshkhHo5Sa5K666iq+/OUvH0n6K1euZPXq1Xzxi18kJSWF2tpalixZwkc+8pERPZz83nvvRUTYvHkz27dvZ+nSpezYsYP77ruPL33pS1xzzTV0dXURDAZ5/vnnmT59Os899xwATU1NYdm32Ej6IraLR6/MVWrqGeSIfLyceuqpVFdXc+DAAWpqakhPTyc3N5d/+qd/Ys2aNbhcLiorKzl06BC5ubnD/t7XXnuN2267DYC5c+dSVFTEjh07OPPMM7n77rupqKjg8ssvZ86cOZSUlHD77bfz1a9+lUsvvZRzzjknLPsWG336YAdza9+D9sZIR6KUmgKuuOIKnnrqKZ588kmuuuoqHnvsMWpqali3bh0bNmwgJyeHjo6OsPzWJz/5SVatWkV8fDyXXHIJf/nLXzjxxBNZv349JSUlfPOb3+Q73/lOWH4rdpJ+70VaBybf/a2VUpPPVVddxRNPPMFTTz3FFVdcQVNTE9OmTcPr9fLKK6+wd+/eEX/nOeecw2OPPQbAjh072LdvHyeddBK7du1i1qxZfPGLX2T58uVs2rSJAwcOkJCQwKc+9SnuuOOOsN2bPza6dwDyTwPEzteffWGko1FKTXLz58+npaWF/Px88vLyuOaaa7jssssoKSmhrKyMuXPnjvg7v/CFL/D5z3+ekpISPB4PDz30EHFxcaxcuZJHH30Ur9dLbm4uX//611m7di133HEHLpcLr9fLL3/5y7DsV3TfT/9Y954BaUVwzcrwfadSKuz0fvrDp/fTH0xBmR3MncQNnVJKjafY6d4BO5j7zv9Aw27ImBXpaJRSUWTz5s18+tOfPqosLi6Ot956K0IR9S+2kn7BYruuKNekr9QkZ4wZ0Rz4SCspKWHDhg0T+puj6Z6Pre6daSeDN1Hn6ys1yfn9furq6kaV1GKFMYa6ujr8fv+IPhdbR/out73jZtXGSEeilBpEQUEBFRUV1NTURDqUSc3v91NQUDCiz8RW0gd7f/13/gd6grYRUEpNOl6vl5kzZ0Y6jKgUW907YI/0A61QvyvSkSil1IQbMumLyIMiUi0iW0LKvisim0Rkg4i8JCLTnXIRkZ+LyE7n/dNCPnOdiLzvLNeNz+4MQ26pXWsXj1IqBg3nSP8hYNkxZT8yxpQaY04BngX+1Sm/GJjjLDcBvwQQkQzgLuAM4HTgLhFJH2vwo5I91z4+Mdy3alVKqSlgyKRvjFkD1B9T1hzyMhHoHWJfDjxirDeBNBHJAy4CXjbG1BtjGoCXOb4hmRgen53Fc3BTRH5eKaUiadQDuSJyN3At0ARc4BTnA/tDqlU4ZQOVR0ZuKex40V6ZO4XmASul1FiNeiDXGPMNY0wh8Bhwa7gCEpGbRKRcRMrHbbpWXim01UJL1fh8v1JKTVLhmL3zGPBxZ7sSKAx5r8ApG6j8OMaY+40xZcaYsuzs7DCE148jg7naxaOUii2jSvoiMifk5XJgu7O9CrjWmcWzBGgyxlQBq4GlIpLuDOAudcoiI3cBINqvr5SKOUP26YvI48D5QJaIVGBn4VwiIicBPcBe4Gan+vPAJcBOoA1YAWCMqReR7wK99z/4jjHmqMHhCRWXbO+9o0lfKRVjhkz6xpir+yl+YIC6BrhlgPceBB4cUXTjKa8UKvUpWkqp2BKVV+QebOrgE/e/wZ/ePTRwpdwSaNyrz8xVSsWUqEz6GYk+Nuxv5LWdtQNXyl1o13qRllIqhkRl0vd5XJQVZfDmrrqBK+U5M3i0X18pFUOiMukDnDEzg+0HW2ho7eq/QtI0SMrVaZtKqZgStUl/yexMAN7eM8gkobxS7d5RSsWUqE36pQWp+L2uwbt4ckuhZjsEOiYuMKWUiqCoTfpxHjenzUjnzV2DHOnnloAJQvW7ExeYUkpFUNQmfYAlszLZfrCZxrYB+vV1MFcpFWOiPukbA2/vHuBoP60Y4lJ0MFcpFTOiOukvLEwlzuMauIvH5bJdPHqkr5SKEVGd9Pv69YcYzD201T4oXSmlolxUJ32wXTzbDjbT1Bbov0JeKQTaoO7vExuYUkpFQAwk/Qzbrz/QfP3cErvWLh6lVAyI+qS/sDANn2eQ+frZc8Htg6qNExuYUkpFQNQnfb/XzWkz0gZO+m6vPihdKRUzoj7pg+3Xf7eqmab2Afr1c0vttE1jJjYwpZSaYDGT9I2BtQPN189bCO310NzvY3uVUipqxETSP2Wofv3eB6XrzdeUUlEuJpK+3+vm1MI03hroSD9nPiB6Za5SKurFRNIH28Wz9UBT//36cUmQOVsHc5VSUS9mkv4ZszLoMVA+0Hz9vFOgcp0O5iqlolrMJP3TZqTjcw/Sr198NrRUQd3OiQ1MKaUmUMwkfb/XzSkzBunXn3muXe/+68QFpZRSEyxmkj7Yfv0tlU00d/TTr58xC1ILYZcmfaVU9IqtpD9zkH59EXu0v+dV6OmZ+OCUUmoCxFTSP/VIv/5AXTznQXsDHNL5+kqp6BRTST/e52Z+fgob9jX2X+FIv/6aCYtJKaUmUkwlfYDS/FS2HGgi2NPP1MyUPMg6Ufv1lVJRa8ikLyIPiki1iGwJKfuRiGwXkU0i8gcRSQt572sislNE3hORi0LKlzllO0XkzrDvyTCVFKTR1hVkd+3h/ivMPBf2/g2CA9ycTSmlprDhHOk/BCw7puxlYIExphTYAXwNQETmAZ8A5juf+S8RcYuIG7gXuBiYB1zt1J1wpQWpAGyqaOq/wszzINBqL9RSSqkoM2TSN8asAeqPKXvJGNPtvHwTKHC2lwNPGGM6jTG7gZ3A6c6y0xizyxjTBTzh1J1ws7OTiPe6B076xWcDov36SqmoFI4+/RuAF5ztfGB/yHsVTtlA5ccRkZtEpFxEymtqasIQ3tHcLmFBfgqbKwdI+gkZ9rm52q+vlIpCY0r6IvINoBt4LDzhgDHmfmNMmTGmLDs7O1xfe5SS/DS2HmiiOzjAfPyZ50LF29DVNi6/r5RSkTLqpC8i1wOXAtcYc+QuZZVAYUi1AqdsoPKIKC1IpSPQw86agQZzz4dgF+x/cyLDUkqpcTeqpC8iy4CvAB8xxoQeDq8CPiEicSIyE5gDvA2sBeaIyEwR8WEHe1eNLfTRKxlqMHfGEnB5tF9fKRV1hjNl83HgDeAkEakQkRuBXwDJwMsiskFE7gMwxmwFVgLvAi8Ctxhjgs6g763AamAbsNKpGxEzMxNJivOweaCkH5cEBYu1X18pFXU8Q1UwxlzdT/EDg9S/G7i7n/LngedHFN04cbmE+dNT2DTQYC7Yfv01P4L2RohPm6jQlFJqXMXcFbm9SgtS2VbVTGDAwdzzwPTA3tcnNjCllBpHMZv0SwrS6OruYcehlv4rFJSBJ1779ZVSUSVmk35pvh3MHbBf3xMHRWdqv75SKqrEbNIvykwg2e8Zul+/Zhscrp64wJRSahzFbNIXEUoLUgc+0gfbrw/axaOUihoxm/TBXpm7/WAznd3B/ivkLQR/qj43VykVNWI66ZcWpBIIGt47OMBgrssNxedov75SKmrEdNIvyR/iylyA2RdC416o2jhBUSml1PiJ6aRfkB5PeoKXLYMN5i643E7dLP/NxAWmlFLjJKaTvohQUpA2+JF+fLpN/Jt/B50DdAMppdQUEdNJH6AkP4Udh1roCAwwmAtQdgN0HbaJXymlpjBN+vlpdPcYtlU1D1wpfxHklkD5g2D6eaC6UkpNETGf9HufmTvgk7QARGDRCji4GSrXT1BkSikVfjGf9PNS/WQl+Qbv1wcovRJ8SfZoXymlpqiYT/oiQkn+EFfmAsQlQ8kVsOVpe7tlpZSagmI+6YO94+b71S20dXUPXrFsBXS3w6YnJyYwpZQKM0362Dtu9hh498Agg7lgb8uQv0gHdJVSU5YmffqemTvoYG6vshugZjvse2Oco1JKqfDTpA/kpPjJSYkbul8fYP7lEJeqA7pKqSlJk76jJD+NDRWNQ1f0JcDCT8C7z0Br3bjHpZRS4aRJ33FaURq7alqpb+0aunLZCgh2wYbHxj8wpZQKI036jsXFGQCs29swdOVpJ8OMf4B1v4GeAR6srpRSk5AmfUdJfio+t4vyPfXD+0DZCqjfBdufHd/AlFIqjDTpO/xeNyUFqZQP50gfYP7HYNp8ePFOvfumUmrK0KQfoqwonc0VTYPfcbOX2wuX/QyaD8Bf7h7/4JRSKgw06YcoK86gK9gzvPn6AIWLYfGN8Pav9EZsSqkpQZN+iEVF6QCsHW6/PsAH/hUSp8EfvwTBIW7joJRSETZk0heRB0WkWkS2hJRdISJbRaRHRMqOqf81EdkpIu+JyEUh5cucsp0icmd4dyM8MhJ9zM5OpHzPMPv1AfypcPEP4OAmeOu+8QtOKaXCYDhH+g8By44p2wJcDqwJLRSRecAngPnOZ/5LRNwi4gbuBS4G5gFXO3UnncXFGazb20BPzwjurTNvOcy5CF65Gxr3jV9wSik1RkMmfWPMGqD+mLJtxpj3+qm+HHjCGNNpjNkN7AROd5adxphdxpgu4Amn7qSzqCidpvYAO2sOD/9DIvDh/7Dbz9+hN2NTSk1a4e7Tzwf2h7yucMoGKj+OiNwkIuUiUl5TUxPm8IbWe5HWiLp4ANJmwAXfgB0v2ls0KKXUJDTpBnKNMfcbY8qMMWXZ2dkT/vtFmQlkJfmGf5FWqDNuhtxSeOGr0DHMGUBKKTWBwp30K4HCkNcFTtlA5ZOOiFBWlMHavaNI+m6PnbvfWg3P3Kq3aFBKTTrhTvqrgE+ISJyIzATmAG8Da4E5IjJTRHzYwd5VYf7tsCkrTmd/fTuHmjtG/uH80+BD34Vtq+BPd4U/OKWUGoPhTNl8HHgDOElEKkTkRhH5mIhUAGcCz4nIagBjzFZgJfAu8CJwizEmaIzpBm4FVgPbgJVO3UmpbLT9+r3OvAUWfxb+9nNY+0AYI1NKqbHxDFXBGHP1AG/9YYD6dwPH3ZfAGPM88PyIoouQ+dNT8HtdlO+t58OleSP/AhFYdo+dvvn8v9hB3jkfCn+gSik1QpNuIHcy8LpdnFKYNvojfbD9+//4IOQsgN9dD1WbwhafUkqNlib9ASwuzuDdqmZaO8dwa4W4JPjkSnvV7m+vhKZJOXatlIohmvQHsKgonWCPYcP+xrF9UUoeXPM76DxsE39Hc1jiU0qp0dCkP4DTitIRGeHN1waSMx+ufBiqt8GjH4OGvWP/TqWUGgVN+gNI8XuZm5syvMcnDscJH4ArHoLaHXDfObDl6fB8r1JKjYAm/UGUFaWzfm8D3cEwXWQ17yNw86uQfSI8dQM8cwt0tYbnu5VSahg06Q+irDid1q4g2w+G8XGI6cWw4gU453Z45zH41Xk6s0cpNWE06Q+i7yKtMPTrh3J77cNXrn0Gug7Drz8Af/uFPoRFKTXuNOkPIj8tnumpftaGq1//WLPOg5tfh9kfgJe+AfefB3vfGJ/fUkopNOkPaVFxBuV76jHjdY/8xEy4+nG44mFob4DfLIM/3AyHq8fn95RSMU2T/hCWzMrgUHMnOw6N4KEqIyUC8z8Kt66Fs/8JNj8F/7kI3rxPu3yUUmGlSX8IS+fl4hJ4dtOB8f8xXyJ88NvwhTegoAxe/Cr86hzbCGjyV0qFgSb9IWQnx3Hm7Eye3VQ1fl08x8qaA5/6PVz5CAS74Okb4T9Phbfu1ymeSqkx0aQ/DJeWTmd3bStbD0zgLRRE7APXb1kLVz0GSbnwwh3wk/nwyvehtXbiYlFKRQ1N+sOwbH4uHpfw7Kaqif9xlwtOvhQ+8zLcsBpmnAl//YFN/s/cClUbJz4mpdSUpUl/GNITfZx1QhbPbT4wcV08/ZmxxM70ueVtKL3K9vX/6lx44CK73d0VudiUUlOCJv1hurQ0j/317WyqmAQPPM8+CT7yc7h9G1z0fTh8yPb7/3SB7fqp3xXpCJVSk5Qm/WFaOi8Xr1smZhbPcMWn20cz3rYernka8k6Bv/4Qfn4q/OJ0ePlf7cVePcFIR6qUmiSGfFyislITvJw7J5vnNlXxtYtPxuWSSIfUx+WCOR+0S+M+2P487HgB3rgXXv8ZxGfAiRfZZdYFEJ8W6YiVUhGiSX8ELl2Yx5+3V/PO/gYWFWVEOpz+pc2AJTfbpaMJdv4Zdrxol42Pg7jtYPCcD8GcpTDtZDtTSCkVEzTpj8AHT87B53Hxx41Vkzfph/KnwoLL7RLshspyeP8l2PES/Okuu6QUwAkXQtFZdqA4rUgbAaWimER0NsoQysrKTHl5eaTDOMrnHi3nnX2NvPG1D+CeTF08I9V8AN5/2TYCu1+FTmeAOjnPJv8ZZ0LhGfapX25vZGNVSo2IiKwzxpT1954e6Y/QpaXTWb31EGv31LNkVmakwxm9lOmw6Dq79ATtoxz3vQH734J9b8LWP9h67jjIXQDTT+1bsk4Ct/7pKDUV6f+5I/SBk6fh97p4dtOBqZ30Q7ncNrHnLoDTP2vLGvfbBqBqAxzYABufhLW/tu954iG3BPIW9i3Zc8Hji9QeKKWGSZP+CCX4PHxgbg4vbjnIty+bj8cdpbNe0wrtUvKP9nVPD9T/HQ68Y5eqjbDxCVj73/Z9t892BU0/DQpPh4LFkDFLxweUmmQ06Y/CpaV5PLe5ird213PWCVmRDmdiuFz2RnBZc6D0SlvW0wMNu/sagaoNsGkllD9g30/I6msA8hbaR0WmFuoZgVIRpEl/FC6YO41En5tnNx2InaTfH5cLMmfb5cgZgTM+UPE27F9ru4jee77vM+KyM4bSi2wjkDETMk+AzDn2zMDrj8iuKBUrhkz6IvIgcClQbYxZ4JRlAE8CxcAe4EpjTIOICPAz4BKgDbjeGLPe+cx1wDedr/2eMebh8O7KxPF73XxwXg4vbDnId5YvwButXTyjETo+UHaDLWutg5rt0LDn6OX9l+wtJI4Qe51B1hzbCKTNcJZCu/anaXeRUmM0nCP9h4BfAI+ElN0J/NkYc4+I3Om8/ipwMTDHWc4Afgmc4TQSdwFlgAHWicgqY8w4PXx2/F1WOp1nNhzgxS0HuWzh9EiHM7klZkLiWVB81vHvdbZA3U6o3Ql170Pt+3a9928QaDu6ri85pCFwlvQiZ7tIrzRWahiGTPrGmDUiUnxM8XLgfGf7YeD/sEl/OfCIsZP/3xSRNBHJc+q+bIypBxCRl4FlwONj34XIuGDuNE7MSeL/vfQeyxbk6tH+aMUl900FDWUMtNVD415o2m9nEzXuc7b3wZ7XoKvl6M/4kiA5115rkJxnt1OmQ0q+7UpKLwZ/ykTtmVKT0mj79HOMMb03lz8I5Djb+cD+kHoVTtlA5ccRkZuAmwBmzJgxyvDGn9slfO3ik1nx0Foef3sf155ZHOmQoouIc4aQCfmnHf++MfZB8o37nGWvveCs+QC0HIT9b9p18JjbTcdn9DUAaYWQkGlvXBefbt+LT4eEDEicZscslIoyYx7INcYYEQnbZb3GmPuB+8FekRuu7x0P55+UzZJZGfzsT+/zsVPzSfbrlasTRsQm54QMmH5K/3V6zxaa9kHDXjuO0OisqzbA9mePbxR6efy2y6i3gciYaddJ0/oaB3+qjjGoKWe0Sf+QiOQZY6qc7ptqp7wSKAypV+CUVdLXHdRb/n+j/O1JQ8Qe7S+/93XuX7OL25eeFOmQVKjQs4Vju4/ANgpdrfaMob0B2uvturW2r3Go3wN7X4euw/18v7vvLCFpmu1SSsmD5Ol96+QcO3XVl6gNhJoURpv0VwHXAfc462dCym8VkSewA7lNTsOwGvi+iKQ79ZYCXxt92JPHwsI0Lls4nV+/uptPLSkiJ0WnHE4ZIhCXZJe0woHrGQNtdbYRaK21jUNbfV9D0VYPrTX2hnbbqiDYefx3uONsV1KC0wglDLLEp9mZStpQqHEwnCmbj2OP0rNEpAI7C+ceYKWI3AjsBZyrdXgeO11zJ3bK5goAY0y9iHwXWOvU+07voG40uGPpSby4pYqf/mkH/355aaTDUeEmAolZdhlK71hD8wFoqbJTUtvq7NJa17fduM+uOwZ5EpvLY5O/P9U2BPEZNoaETKdrK9OeRRxpTLJsfR2LUIPQu2yGyb/9cSsP/20Pq798LnNykiMdjpoqggHbSLTV2bOItjroaIT2RrvuaOrbbnPOKtpqj5/O2ktczmB0ljPukGJnSMWFrP0pxwxcO9s6RhE19C6bE+C2C+fwVHkFP3hxO7++bnGkw1FThdtrxwOSpo3sc11ttmupt6Foq+87i2gLKTtcDXV/t9dDdDZDd8fA3ynuYxqI5KMbDX+KbRjiUvrOQI6chaTbMr3FxqSnST9MMhJ93Hz+bH60+j3e2lXHGdFyB041OfkS7JJaMLLPdXfZ5N87eN1W3zeA3VbvNA5OA9HZbMcqehuNjsaBZzv18ib0zWzyJdrXviQn3kTwJoI33t5uwxPvbDtLXDLEpR7duHjj9ewjzDTph9ENZ83k0Tf28v0XtvO/X/gHRP9Y1WTj8YFnmOMT/Ql02Mago8lZGm33U3tDyHaj3Q602dlRbfV29lNXqy0LtIHpGd7vubzOGYfTGMSl9J1hxCXbqbXehKMbD29C39mKP+SsxZes4x1o0g+reJ+bf156Il95ahO/X1/JxxeN8ChMqcnO67fLSLujQhljxzICbba7KdAGgXbnbMI5w+hoDNl2Gpne7fpddt3VYhuh/mZLDcSX7MzYSg5pDJKchqP37CNk7U20ZynehJAzl4SQcmft8U+ZMxJN+mH28dMK+F35fr7+h82cMC2JhYVpkQ5JqclFxDnjCFP/f0/QNhqB9r4ziSNdVL0NSe/rw33lvUvLob4GqLtj5A0J2AF0b0jj0LsceZ1k13FJznbo65CGyJfknKUkgScuPP8+x4aqs3fCr+5wJx/9r9fpCPTwzC1nMT0tPtIhKaVGoqfHaQDaIdBqB84DrbaL6sh2W18XVqDt6PKu1pD6rbaxCTjr4TYoBYvhM38aVfg6e2eCZSbF8cB1i/n4f/2NGx8u56mbzyQxTv+plZoyXK6+wXLCPCkjGLBjHJ2H+8Y6jpyFtDjvNdtpt+NAM9E4OTEnmV9ccxorfvM2X3riHX716TLcrqnR56eUGkdub9/tOyJAh7LH0XknZvPtj8znT9uqueeFbZEORyml9Eh/vF17ZjF/rz7Mf7+6m1nZSVx9+uS9XbRSKvpp0p8A37p0Hrvr2vjW/26hID2ec+ZkRzokpVSM0u6dCeBxu/jFJ09ldnYSNzy0lifX7ot0SEqpGKVJf4Kk+L2s/NyZLJmVyVef3sy3V22lOzjMqxKVUipMNOlPoNQEL7+5fjE3nj2Th/62h+t+8zYNrUPcy0QppcJIk/4E87hdfOvSefzHFQtZu7uB5fe+zo5DLUN/UCmlwkCTfoT846ICnvjcEtoDQT527+u8uKVq6A8ppdQYadKPoNNmpPPHW8/mhGlJ3Pw/6/nco+VUNAzwcAyllAoDTfoRlpvqZ+XNZ/KVZSexZkctH/zxX/nFX96nszsY6dCUUlFIk/4kEOdx84XzT+BPt5/HBSdN4z9e2sGyn77KX3fURDo0pVSU0aQ/ieSnxfPLTy3ikRtOR4DrHnybzz1azpbKQR6erZRSI6C3Vp6kOruD/PrV3fzy//7O4c5uzj4hi8+dN4uzT8jSJ3IppQY12K2VNelPck3tAX771j5+8/puqls6mZeXwufOm8UlJXl43XqippQ6nib9KNDZHeSZdw5w/6u72Fl9mPy0eK5aXMjlp+VTkJ4Q6fCUUpOIJv0o0tNj+Mv2ah54bTdv7KoD4B9mZ3JFWQHL5ucR73NHOEKlVKRp0o9S++vb+P36Sp5av5/99e0kxXn4cEkely2czhmzMrT7R6kYpUk/yvX0GNbuqeepdRU8t7mKtq4gKX4PF86dxtL5uZx3YrY+rlGpGKJJP4a0dwV5bWctq7ce5M/bDtHQFsDncXH2CVlcOHca58zJoigzMdJhKqXG0bg9GF1EvgR8FhDgv40xPxWRDOBJoBjYA1xpjGkQO8/wZ8AlQBtwvTFm/Vh+Xx0v3ufmQ/Ny+NC8HLqDPZTvbeClrYd46d2D/GV7NQCFGfGcfUIWZ52QxVmzs0hP9EU4aqXURBn1kb6ILACeAE4HuoAXgZuBm4B6Y8w9InInkG6M+aqIXALchk36ZwA/M8acMdhv6JF++Bhj2FXbyus7a3n1/Vre/HsdLZ3diMDJuSksLk6nrDiDsuJ08lLjIx2uUmoMxqV7R0SuAJYZY250Xn8L6ARuBM43xlSJSB7wf8aYk0TkV872407993rrDfQbmvTHT3ewh40VTby+s5Y3d9Xxzr5G2gP2fj/5afEsKkqnrDid0oI05uYm4/fqrCClporx6t7ZAtwtIplAO/YIvhzICUnkB4EcZzsf2B/y+Qqn7KikLyI3Yc8WmDFDHyI+XjxuF4uK0llUlM4XPzCHQLCHbVXNlO9pYN3eBt7aXceqjQdsXZdwYk4yJfmplBSkUpKfyknaECg1JY066RtjtonID4CXgFZgAxA8po4RkRGdShhj7gfuB3ukP9r41Mh43S5KC9IoLUjjhrNnYoyhsrGdLZVNbKpoYnNlE6vfPciT5bbddgnMzErk5LwUTs5LYW5uMnPzUpie6tfbRCg1iY1pINcY8wDwAICIfB979H5IRPJCuneqneqVQGHIxwucMjUJiQgF6QkUpCewbEEeYMcFKhra2VzZxPaqZrYdbGFjRSPPbuo7WUuK8zB7WhJzepecJE7ITqYgPR6XSxsDpSJtrLN3phljqkVkBnA5sASYCVwH3OOsn3GqrwJuFZEnsAO5TYP156vJR0QozEigMCOBS0ryjpS3dATYcaiFbVUt7Kw+zPvVLazZUcNT6yqO1InzuCjOTGRWdiIzsxKZlZ1k11mJpCV49exAqQky1it2nnb69APALcaYRhG5B1gpIjcCe4ErnbrPY/v9d2KnbK4Y42+rSSLZ72VRUQaLijKOKm9qC7CzpoUdhw6zq+Ywu2tbee9gCy+/e4juHhPyeQ9FmQnMyEhgRkYiRZkJFDmNS16qH49eWaxU2OjFWWrCBYI9VDS0H2kI9tW3sbeujX31bVQ0tBEI9v1Nul1Cboqfwox4p7spnvy0eKY7S16qXweUlTrGuF2cpdRoeN0uZmbZbp5jBXsMBxrbjzQAFQ3t7K+369fer+VQSwfHHqdkJvqONAC5zpKX6ic3Jd6+TvHrjeiUcmjSV5OK29U3btCfzu4gh5o6qWxs50Dv0tRBZWM7e+paeXNXHc0d3cd9LtnvISfFT05KHDnJfrJ718lxTEuOs+sUP4k+t44vqKimSV9NKXEeNzMyE5iROfAzBFo7uznY3MGhpg6qmjo42NxBdXMHh5o7qW7p4K3d9VS3dBzVjdQr3utmWkocWUlxZCfFkZXss9vJtiwryUdmYhwZST6S4zzaQKgpR5O+ijqJcR5mZycxOztpwDo9PYbG9gA1LbYhsOvOI+valk7+XnOYN3d30tgW6Pc7fG4XmUk+MhKPWRJ8pCf6yEy06/QEH+mJXtITfHq7axVxmvRVTHK55EiSPik3edC6Xd091Ld2UdPSSV1rJ3WHu+y6tctuH+6kvi3A3ro2Glq7aOk8vnupV3KchzSnAUhL8JGe4CUt3tu3neAjrXcd7yU13ktKvBe3XuOgwkSTvlJD8HlcRwaIh6OzO0hjW4D61i7qW7toaOuioS1AQ+92q33d2NbFntpWGtu6+h2HCJXi95Ca4CUt3kdqvJfUBNsghC4pfi8p8R5n7SXF7yHZ78Xn0bML1UeTvlJhFudxk5PiJidleI0E2BvgNbUHaGgL0NQeoKm9i0Znu9FpIGx5gMb2AAea2ml23gu95qE/8V73UY1Bst9uJzuNQkq8s/Z7jpQlxR29rWca0UOTvlKTgMftIjMpjsykuBF9zhhDeyBIU3uA5vZumjsCNDuNQ3N7gJaO3jJn3RGg7rA9w+h9r78B7WMl+twk+T0kxXlIchqIpDi7JDoNRGLc0WWJce4jr3vLEnR2VMRp0ldqChMREnweEnwe8lJH/nljDJ3dPTR32AbCLgEOO9u95a2d3RzudN7v7OZwR4BDzR20dNjy1s5uhjjhcOKFBK/7SAPR2xCENhQJPg+JPlsnIc5uJ/hC3otzk+jzEO+za7/XpQ3JCGjSVyqGiQh+rxu/1820wcezB9V7xnG4s5vDHd20djrbnX0NRt86SFtXX1lrV5CDzR20dQVp7ey2667u4y7CG3gfbEOS4DQg8U6j0rud4HMT77Ov7bbb1ncajt6y+N4yr/PaKYu2ri1N+kqpMQs94xhL49Grp8fQ0W0bjvau4JGGorUrSFtIw9B21Osg7U6d9i772ZqWTluny36+PRAcdmPSy+dx2YbAaUD83r4G4cja2fYf2bafifMe+77rSJ3QdZzHNWF3odWkr5SadFyuvkYknHq7s440Ak6D0B6wDUV7IPR1N+1dPbQFuukIea8j0NeI1LV2Oa+7j3x+OGMk/YnzhDYILkoK0vjPq08N6/6DJn2lVAwJ7c7KSPSNy290B3vo6O6hw2lIOkIai47uniNlHQHbSHQEemgPBOkM9Jb30NEdpCB9fJ5VrUlfKaXCyON2keR2kRQ3OdOrXrWhlFIxRJO+UkrFEE36SikVQzTpK6VUDNGkr5RSMUSTvlJKxRBN+kopFUM06SulVAwRM9IbUUwgEakB9o7hK7KA2jCFM5XofscW3e/YMpz9LjLGZPf3xqRO+mMlIuXGmLJIxzHRdL9ji+53bBnrfmv3jlJKxRBN+kopFUOiPenfH+kAIkT3O7bofseWMe13VPfpK6WUOlq0H+krpZQKoUlfKaViSFQmfRFZJiLvichOEbkz0vGMJxF5UESqRWRLSFmGiLwsIu876/RIxhhuIlIoIq+IyLsislVEvuSUR/t++0XkbRHZ6Oz3vznlM0XkLefv/UkRGZ9HQkWYiLhF5B0RedZ5HSv7vUdENovIBhEpd8pG/bcedUlfRNzAvcDFwDzgahGZF9moxtVDwLJjyu4E/myMmQP82XkdTbqB240x84AlwC3Of+No3+9O4EJjzELgFGCZiCwBfgD8xBhzAtAA3Bi5EMfVl4BtIa9jZb8BLjDGnBIyP3/Uf+tRl/SB04Gdxphdxpgu4AlgeYRjGjfGmDVA/THFy4GHne2HgY9OZEzjzRhTZYxZ72y3YBNBPtG/38YYc9h56XUWA1wIPOWUR91+A4hIAfBh4NfOayEG9nsQo/5bj8aknw/sD3ld4ZTFkhxjTJWzfRDIiWQw40lEioFTgbeIgf12ujg2ANXAy8DfgUZjTLdTJVr/3n8KfAXocV5nEhv7DbZhf0lE1onITU7ZqP/WJ+eTe1XYGGOMiETlvFwRSQKeBr5sjGm2B39WtO63MSYInCIiacAfgLmRjWj8icilQLUxZp2InB/hcCLhbGNMpYhMA14Wke2hb470bz0aj/QrgcKQ1wVOWSw5JCJ5AM66OsLxhJ2IeLEJ/zFjzO+d4qjf717GmEbgFeBMIE1Eeg/govHv/SzgIyKyB9tdeyHwM6J/vwEwxlQ662psQ386Y/hbj8akvxaY44zs+4BPAKsiHNNEWwVc52xfBzwTwVjCzunPfQDYZoz5cchb0b7f2c4RPiISD3wIO57xCvCPTrWo229jzNeMMQXGmGLs/89/McZcQ5TvN4CIJIpIcu82sBTYwhj+1qPyilwRuQTbB+gGHjTG3B3ZiMaPiDwOnI+93eoh4C7gf4GVwAzsramvNMYcO9g7ZYnI2cCrwGb6+ni/ju3Xj+b9LsUO2rmxB2wrjTHfEZFZ2CPgDOAd4FPGmM7IRTp+nO6dfzHGXBoL++3s4x+clx7gt8aYu0Ukk1H+rUdl0ldKKdW/aOzeUUopNQBN+kopFUM06SulVAzRpK+UUjFEk75SSsUQTfpKKRVDNOkrpVQM+f8BFwfR+2Ro9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], label=\"loss\")\n",
    "plt.plot(hist.history['val_loss'], label=\"val_loss\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
